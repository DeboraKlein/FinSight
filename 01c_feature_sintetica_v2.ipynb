{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74287281",
   "metadata": {},
   "source": [
    "## Código Python para Geração da Base Sintética"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "959a477d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando simulação para 10000 clientes em 24 meses...\n",
      "Perfis estáticos criados:\n",
      "grupo_simulacao\n",
      "instavel            0.6361\n",
      "estavel_controle    0.2882\n",
      "estavel_target      0.0757\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Dados macro carregados. Último mês: 2025-09-01\n",
      "\n",
      "Criando features de janela móvel (tendência)...\n",
      "Criando variável alvo...\n",
      "\n",
      "Salvando base de ML final em formato Parquet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\debor\\AppData\\Local\\Temp\\ipykernel_32512\\688258002.py:280: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ml['entrou_rotativo_proximo_mes'] = df_ml['entrou_rotativo_proximo_mes'].astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucesso! Base salva em 'base_simulada_clientes.parquet'\n",
      "Este formato preserva 100% dos tipos de dados (datas, números, etc.).\n",
      "\n",
      "--- Base de ML pronta para treinamento! ---\n",
      "\n",
      "Exemplo de um cliente 'estável_target' (ID: 18):\n",
      "    mes_referencia  gasto_total_cartao  pagamento_fatura  gasto_crescim_3m  \\\n",
      "421     2025-01-01          332.100370        332.100370          0.090640   \n",
      "422     2025-02-01          290.818385        290.818385         -0.203270   \n",
      "423     2025-03-01          557.372931        557.372931         -0.199726   \n",
      "424     2025-04-01          306.918906        306.918906          0.416700   \n",
      "425     2025-05-01         1033.375586        272.215145         -0.202884   \n",
      "426     2025-06-01         1429.195866        420.839533          0.633651   \n",
      "427     2025-07-01         1058.814450        237.244957          0.548150   \n",
      "428     2025-08-01         1503.114445        364.976401         -0.097956   \n",
      "429     2025-09-01         1354.132290        231.276682          0.129843   \n",
      "430     2025-10-01         1258.312537        323.936622          0.037368   \n",
      "\n",
      "     scr_crescim_divida_3m  entrou_rotativo_proximo_mes  \n",
      "421              -0.003549                            0  \n",
      "422              -0.002715                            0  \n",
      "423               0.013466                            0  \n",
      "424               0.011667                            1  \n",
      "425               0.006397                            1  \n",
      "426               0.222872                            1  \n",
      "427               0.252826                            1  \n",
      "428               0.224261                            1  \n",
      "429               0.265412                            1  \n",
      "430               0.193243                            1  \n",
      "\n",
      "Distribuição da variável alvo (Target):\n",
      "entrou_rotativo_proximo_mes\n",
      "0    0.784874\n",
      "1    0.215126\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "--- Divisão Cronológica da Base (Split no mês 18) ---\n",
      "Treino (Meses 1-17): 170000 observações\n",
      "Teste (Meses 18-24): 60000 observações\n",
      "\n",
      "Modelo treinado com sucesso (RandomForest com class_weight='balanced').\n",
      "\n",
      "--- Relatório de Classificação (Threshold ajustado para 0.2) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.41      0.53     43961\n",
      "           1       0.29      0.66      0.40     16039\n",
      "\n",
      "    accuracy                           0.48     60000\n",
      "   macro avg       0.53      0.54      0.47     60000\n",
      "weighted avg       0.64      0.48      0.50     60000\n",
      "\n",
      "\n",
      "AVISO: LightGBM não instalado. Usando RandomForest.\n",
      "\n",
      "--- Relatório de Classificação (Threshold ajustado para 0.2) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.43      0.55     43961\n",
      "           1       0.29      0.65      0.40     16039\n",
      "\n",
      "    accuracy                           0.49     60000\n",
      "   macro avg       0.53      0.54      0.48     60000\n",
      "weighted avg       0.64      0.49      0.51     60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "# --- 1. CONFIGURAÇÃO DA SIMULAÇÃO ---\n",
    "\n",
    "N_CLIENTES = 10000     # Número de clientes para simular\n",
    "N_MESES = 24           # Histórico de 24 meses\n",
    "MES_INICIO_ESTRESSE = 18 # Mês em que o \"evento de estresse\" começa\n",
    "PCT_ESTRESSE = 0.20    # % de clientes bons que sofrerão o evento de estresse\n",
    "\n",
    "# Probabilidades demográficas baseadas nos relatórios (Serasa & ANBIMA)\n",
    "# [18-25, 26-40, 41-65, >65]\n",
    "PROB_IDADE = [0.113, 0.338, 0.354, 0.195]\n",
    "# [Classe A/B, Classe C, Classe D/E]\n",
    "PROB_CLASSE = [0.24, 0.47, 0.29]\n",
    "# [Sudeste, Nordeste, Sul, Norte, C.Oeste]\n",
    "PROB_REGIAO = [0.43, 0.26, 0.15, 0.08, 0.08]\n",
    "\n",
    "print(f\"Iniciando simulação para {N_CLIENTES} clientes em {N_MESES} meses...\")\n",
    "\n",
    "# --- 2. FUNÇÃO PARA CRIAR OS PERFIS ESTÁTICOS ---\n",
    "def criar_clientes_estaticos(n_clientes):\n",
    "    \"\"\"\n",
    "    Cria a base inicial de clientes com seus perfis demográficos e financeiros\n",
    "    que não mudam (ou mudam pouco) ao longo do tempo.\n",
    "    \"\"\"\n",
    "    df_clientes = pd.DataFrame(\n",
    "        index=np.arange(1, n_clientes + 1),\n",
    "        columns=[\n",
    "            'id_cliente', 'idade_faixa', 'classe_social', 'regiao', \n",
    "            'perfil_investidor', 'limite_cartao', 'scr_divida_inicial', \n",
    "            'grupo_simulacao'\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    df_clientes['id_cliente'] = np.arange(1, n_clientes + 1)\n",
    "    \n",
    "    # --- Demografia (Baseado nos relatórios) ---\n",
    "    df_clientes['idade_faixa'] = np.random.choice(\n",
    "        ['18-25', '26-40', '41-65', '65+'], n_clientes, p=PROB_IDADE\n",
    "    )\n",
    "    df_clientes['classe_social'] = np.random.choice(\n",
    "        ['A/B', 'C', 'D/E'], n_clientes, p=PROB_CLASSE\n",
    "    )\n",
    "    df_clientes['regiao'] = np.random.choice(\n",
    "        ['Sudeste', 'Nordeste', 'Sul', 'Norte', 'Centro-Oeste'], n_clientes, p=PROB_REGIAO\n",
    "    )\n",
    "    \n",
    "    # --- Perfil Financeiro (Definindo seus clientes \"estáveis\") ---\n",
    "    # Vamos usar o Perfil ANBIMA para definir quem é \"estável\"\n",
    "    probs_perfil = {'A/B': [0.36, 0.22, 0.13, 0.29], # [Diversifica, Caderneta, Economiza, Sem Reserva]\n",
    "                    'C':   [0.13, 0.22, 0.15, 0.50],\n",
    "                    'D/E': [0.05, 0.15, 0.09, 0.71]}\n",
    "    \n",
    "    df_clientes['perfil_investidor'] = df_clientes['classe_social'].apply(\n",
    "        lambda x: np.random.choice(['Diversifica', 'Caderneta', 'Economiza', 'Sem Reserva'], p=probs_perfil[x])\n",
    "    )\n",
    "    \n",
    "    # --- Definir Limites e Dívidas Iniciais (Baseado na Classe Social) ---\n",
    "    limites = {'A/B': (10000, 30000), 'C': (3000, 10000), 'D/E': (500, 3000)}\n",
    "    dividas = {'A/B': (1000, 5000), 'C': (500, 2000), 'D/E': (0, 500)}\n",
    "    \n",
    "    df_clientes['limite_cartao'] = df_clientes['classe_social'].apply(lambda x: np.random.uniform(*limites[x]))\n",
    "    df_clientes['scr_divida_inicial'] = df_clientes['classe_social'].apply(lambda x: np.random.uniform(*dividas[x]))\n",
    "\n",
    "    # --- GRUPO DE SIMULAÇÃO (O PULO DO GATO) ---\n",
    "    # 1. estavel_target: Seus clientes \"bons\" que VÃO sofrer estresse (Seu alvo)\n",
    "    # 2. estavel_controle: Clientes \"bons\" que NÃO vão sofrer estresse (Controle)\n",
    "    # 3. instavel: Clientes \"ruins\" (não são seu alvo, mas bons para o modelo aprender)\n",
    "    \n",
    "    def definir_grupo(row):\n",
    "        # Clientes \"instáveis\" (Perfil Sem Reserva ou Economiza)\n",
    "        if row['perfil_investidor'] in ['Sem Reserva', 'Economiza']:\n",
    "            return 'instavel'\n",
    "        # Clientes \"estáveis\" (Perfil Diversifica ou Caderneta)\n",
    "        else:\n",
    "            # Vamos sortear uma parte deles para o grupo de estresse\n",
    "            if np.random.rand() < PCT_ESTRESSE:\n",
    "                return 'estavel_target'\n",
    "            else:\n",
    "                return 'estavel_controle'\n",
    "                \n",
    "    df_clientes['grupo_simulacao'] = df_clientes.apply(definir_grupo, axis=1)\n",
    "    \n",
    "    print(\"Perfis estáticos criados:\")\n",
    "    print(df_clientes['grupo_simulacao'].value_counts(normalize=True))\n",
    "    \n",
    "    return df_clientes.set_index('id_cliente')\n",
    "\n",
    "\n",
    "# --- 3. CARREGAR DADOS MACRO (Seus arquivos do BC) ---\n",
    "def carregar_dados_macro():\n",
    "    \"\"\"\n",
    "    Carrega os dados de juros e inadimplência dos arquivos CSV.\n",
    "    Isso dará contexto macroeconômico para cada mês da simulação.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Juros rotativo (20679), Juros pessoal (20665), Inadimplência PF (21084)\n",
    "        df_rotativo = pd.read_csv('bcdata.sgs.20679.csv', sep=';', decimal=',', parse_dates=['data'], dayfirst=True)\n",
    "        df_pessoal = pd.read_csv('bcdata.sgs.20665.csv', sep=';', decimal=',', parse_dates=['data'], dayfirst=True)\n",
    "        df_inadimp = pd.read_csv('bcdata.sgs.21084.csv', sep=';', decimal=',', parse_dates=['data'], dayfirst=True)\n",
    "        \n",
    "        # Limpando e formatando\n",
    "        df_rotativo['taxa_juros_rotativo'] = df_rotativo['valor'] / 100 # Assumindo que 12798 é 127,98%\n",
    "        df_pessoal['taxa_juros_pessoal'] = df_pessoal['valor'] / 100 # Assumindo que 23978 é 239,78%\n",
    "        df_inadimp['taxa_inadimplencia_pf'] = df_inadimp['valor']\n",
    "        \n",
    "        # Criando uma base macro mensal\n",
    "        df_macro = df_rotativo[['data', 'taxa_juros_rotativo']].merge(\n",
    "            df_pessoal[['data', 'taxa_juros_pessoal']], on='data'\n",
    "        ).merge(\n",
    "            df_inadimp[['data', 'taxa_inadimplencia_pf']], on='data'\n",
    "        )\n",
    "        \n",
    "        # Criando um 'mes_id' para fazer o merge com a simulação\n",
    "        df_macro = df_macro.sort_values('data').reset_index(drop=True)\n",
    "        df_macro['mes_id'] = (df_macro['data'].dt.year - df_macro['data'].dt.year.min()) * 12 + df_macro['data'].dt.month\n",
    "        \n",
    "        # Pegando apenas os N_MESES mais recentes para a simulação\n",
    "        df_macro = df_macro.tail(N_MESES).reset_index(drop=True)\n",
    "        df_macro['mes_simulacao'] = np.arange(1, N_MESES + 1)\n",
    "        \n",
    "        print(f\"\\nDados macro carregados. Último mês: {df_macro['data'].max().date()}\")\n",
    "        return df_macro[['mes_simulacao', 'taxa_juros_rotativo', 'taxa_juros_pessoal', 'taxa_inadimplencia_pf']]\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"\\nArquivos CSV do Banco Central não encontrados. Rodando sem dados macro.\")\n",
    "        return None\n",
    "\n",
    "# --- 4. FUNÇÃO PARA GERAR O HISTÓRICO COMPORTAMENTAL ---\n",
    "def gerar_historico_longitudinal(df_clientes, df_macro):\n",
    "    \"\"\"\n",
    "    Cria o histórico de transações mês a mês para cada cliente,\n",
    "    simulando o comportamento de cada 'grupo_simulacao'.\n",
    "    \"\"\"\n",
    "    historico_total = []\n",
    "    \n",
    "    # Datas da simulação\n",
    "    datas_mes = pd.date_range(end=datetime.date.today(), periods=N_MESES, freq='MS')\n",
    "    \n",
    "    for id_cliente, perfil in df_clientes.iterrows():\n",
    "        \n",
    "        # Parâmetros do cliente\n",
    "        grupo = perfil['grupo_simulacao']\n",
    "        limite = perfil['limite_cartao']\n",
    "        divida_scr_atual = perfil['scr_divida_inicial']\n",
    "        \n",
    "        for mes_num in range(1, N_MESES + 1):\n",
    "            \n",
    "            # --- Parâmetros base de simulação ---\n",
    "            gasto_cartao = 0\n",
    "            pagamento_fatura = 0\n",
    "            flag_rotativo = False\n",
    "            \n",
    "            # --- LÓGICA DE COMPORTAMENTO ---\n",
    "            \n",
    "            if grupo == 'instavel':\n",
    "                # Cliente \"ruim\": gasta muito e paga parcial aleatoriamente\n",
    "                gasto_cartao = limite * np.random.uniform(0.5, 1.0)\n",
    "                if np.random.rand() < 0.3: # 30% de chance de pagar parcial\n",
    "                    pagamento_fatura = gasto_cartao * np.random.uniform(0.15, 0.5)\n",
    "                    flag_rotativo = True\n",
    "                else:\n",
    "                    pagamento_fatura = gasto_cartao\n",
    "                # Dívida SCR cresce erraticamente\n",
    "                divida_scr_atual *= np.random.uniform(0.95, 1.1)\n",
    "\n",
    "            elif grupo == 'estavel_controle':\n",
    "                # Cliente \"bom\" (controle): gasta pouco e paga integral\n",
    "                gasto_cartao = limite * np.random.uniform(0.2, 0.5)\n",
    "                pagamento_fatura = gasto_cartao\n",
    "                flag_rotativo = False\n",
    "                # Dívida SCR controlada\n",
    "                divida_scr_atual *= np.random.uniform(0.98, 1.02)\n",
    "                \n",
    "            elif grupo == 'estavel_target':\n",
    "                # Cliente \"bom\" (alvo): se comporta bem ATÉ o estresse\n",
    "                if mes_num < MES_INICIO_ESTRESSE:\n",
    "                    # Comportamento normal\n",
    "                    gasto_cartao = limite * np.random.uniform(0.2, 0.5)\n",
    "                    pagamento_fatura = gasto_cartao\n",
    "                    flag_rotativo = False\n",
    "                    divida_scr_atual *= np.random.uniform(0.98, 1.02)\n",
    "                else:\n",
    "                    # **EVENTO DE ESTRESSE (SUAS FEATURES!)**\n",
    "                    # 1. Aumento do uso do cartão\n",
    "                    gasto_cartao = limite * np.random.uniform(0.7, 1.1) # Gasto sobe!\n",
    "                    # 2. Aumento do endividamento no SCR\n",
    "                    divida_scr_atual *= np.random.uniform(1.1, 1.4) # Dívida externa sobe!\n",
    "                    \n",
    "                    # CONSEQUÊNCIA: Cliente não consegue pagar\n",
    "                    pagamento_fatura = gasto_cartao * np.random.uniform(0.15, 0.3) # Paga só o mínimo\n",
    "                    flag_rotativo = True\n",
    "            \n",
    "            historico_total.append({\n",
    "                'id_cliente': id_cliente,\n",
    "                'mes_referencia': datas_mes[mes_num-1],\n",
    "                'mes_simulacao': mes_num,\n",
    "                'gasto_total_cartao': gasto_cartao,\n",
    "                'pagamento_fatura': pagamento_fatura,\n",
    "                'utilizacao_limite_cartao': gasto_cartao / limite,\n",
    "                'flag_rotativo': flag_rotativo,\n",
    "                'scr_saldo_devedor_total': divida_scr_atual\n",
    "            })\n",
    "            \n",
    "    df_hist = pd.DataFrame(historico_total)\n",
    "    \n",
    "    # Juntar dados macroeconômicos ao histórico\n",
    "    if df_macro is not None:\n",
    "        df_hist = df_hist.merge(df_macro, on='mes_simulacao', how='left')\n",
    "        \n",
    "    return df_hist.merge(df_clientes, on='id_cliente', how='left')\n",
    "\n",
    "\n",
    "# --- 5. FUNÇÃO PARA CRIAR AS FEATURES DE JANELA MÓVEL (SUAS INSIGHTS) ---\n",
    "def criar_features_janeladas(df):\n",
    "    \"\"\"\n",
    "    Cria as features de tendência (últimos 3 meses) que o modelo usará.\n",
    "    Garante o alinhamento correto dos índices para evitar o ValueError.\n",
    "    \"\"\"\n",
    "    print(\"\\nCriando features de janela móvel (tendência)...\")\n",
    "    \n",
    "    # 1. Ordenar o DataFrame (mantendo a ordenação por cliente e mês)\n",
    "    df = df.sort_values(['id_cliente', 'mes_referencia'])\n",
    "    \n",
    "    # 2. Criar o índice composto (id_cliente + índice numérico)\n",
    "    # Isso garante que o índice do df corresponda ao índice gerado pelo .groupby()\n",
    "    df_indexed = df.set_index(['id_cliente', df.index]) # Novo DF temporário com MultiIndex\n",
    "    \n",
    "    # 3. Configurar o agrupamento no DataFrame original (para preservar as colunas)\n",
    "    g = df.groupby('id_cliente')\n",
    "    \n",
    "    # --- CÁLCULO DAS FEATURES ---\n",
    "    \n",
    "    # Os resultados do .rolling() (gasto_media_3m, scr_media_3m, etc.) \n",
    "    # terão o MultiIndex. Usamos o .reset_index(level=0, drop=True) \n",
    "    # para retornar apenas a parte do índice que corresponde ao índice original do DF.\n",
    "    \n",
    "    # 1. \"aumento no uso do cartao de crédito\"\n",
    "    gasto_media_3m = g['gasto_total_cartao'].rolling(window=3, min_periods=1).mean().shift(1).reset_index(level=0, drop=True)\n",
    "    gasto_ult_mes = g['gasto_total_cartao'].shift(1).reset_index(level=0, drop=True)\n",
    "    \n",
    "    df['gasto_crescim_3m'] = (gasto_ult_mes / gasto_media_3m) - 1\n",
    "    \n",
    "    # 2. \"aumento do endividamento no scr\"\n",
    "    scr_media_3m = g['scr_saldo_devedor_total'].rolling(window=3, min_periods=1).mean().shift(1).reset_index(level=0, drop=True)\n",
    "    scr_ult_mes = g['scr_saldo_devedor_total'].shift(1).reset_index(level=0, drop=True)\n",
    "    \n",
    "    df['scr_crescim_divida_3m'] = (scr_ult_mes / scr_media_3m) - 1\n",
    "    \n",
    "    # --- Outras features de suporte importantes ---\n",
    "    \n",
    "    df['utilizacao_limite_media_3m'] = g['utilizacao_limite_cartao'].rolling(window=3, min_periods=1).mean().shift(1).reset_index(level=0, drop=True)\n",
    "    df['contagem_rotativo_3m'] = g['flag_rotativo'].rolling(window=3, min_periods=1).sum().shift(1).reset_index(level=0, drop=True)\n",
    "\n",
    "    # Preenchendo NaNs e corrigindo infinitos\n",
    "    df = df.fillna(0)\n",
    "    df = df.replace([np.inf, -np.inf], 0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# --- 6. FUNÇÃO PARA CRIAR A VARIÁVEL ALVO (TARGET) ---\n",
    "def criar_variavel_alvo(df):\n",
    "    \"\"\"\n",
    "    Cria a coluna 'target' que o modelo de ML tentará prever.\n",
    "    Nosso alvo é: \"O cliente VAI entrar no rotativo no PRÓXIMO mês?\"\n",
    "    \"\"\"\n",
    "    print(\"Criando variável alvo...\")\n",
    "    df = df.sort_values(['id_cliente', 'mes_referencia'])\n",
    "    \n",
    "    # Usamos shift(-1) para trazer o futuro (\"próximo mês\") para a linha atual.\n",
    "    df['entrou_rotativo_proximo_mes'] = df.groupby('id_cliente')['flag_rotativo'].shift(-1)\n",
    "    \n",
    "    # Removemos o último mês de cada cliente, pois não temos o \"próximo\" mês para ele.\n",
    "    df_ml = df.dropna(subset=['entrou_rotativo_proximo_mes'])\n",
    "    \n",
    "    # Convertendo para 0/1\n",
    "    df_ml['entrou_rotativo_proximo_mes'] = df_ml['entrou_rotativo_proximo_mes'].astype(int)\n",
    "    \n",
    "    return df_ml\n",
    "\n",
    "# --- 7. FUNÇÃO DE ORQUESTRAÇÃO (MAIN) ---\n",
    "def main():\n",
    " \n",
    "    # Passo 1: Criar perfis estáticos\n",
    "    # NOTE: df_clientes é criado AQUI\n",
    "    df_clientes = criar_clientes_estaticos(N_CLIENTES)\n",
    " \n",
    "    # Passo 2: Carregar dados macro\n",
    "    df_macro = carregar_dados_macro()\n",
    "\n",
    "    # Passo 3: Gerar histórico\n",
    "    df_historico_completo = gerar_historico_longitudinal(df_clientes, df_macro)\n",
    "\n",
    "    # Passo 4: Criar features de tendência (Suas insights!)\n",
    "    df_features = criar_features_janeladas(df_historico_completo)\n",
    "\n",
    "    # Passo 5: Criar a variável alvo\n",
    "    df_base_ml = criar_variavel_alvo(df_features)\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # --- PASSO 6: SALVAR A BASE FINAL (DENTRO DA FUNÇÃO) ---\n",
    "    # ----------------------------------------------------------------------\n",
    "\n",
    "    print(f\"\\nSalvando base de ML final em formato Parquet...\")\n",
    "    try:\n",
    "        # ... (código de salvamento) ...\n",
    "        df_base_ml.to_parquet('base_simulada_clientes.parquet', index=False)\n",
    "        print(\"Sucesso! Base salva em 'base_simulada_clientes.parquet'\")\n",
    "        print(\"Este formato preserva 100% dos tipos de dados (datas, números, etc.).\")\n",
    "\n",
    "    except ImportError:\n",
    "    # ... (código de salvamento CSV) ...\n",
    "        print(\"Biblioteca 'pyarrow' ou 'fastparquet' não encontrada. Salvando em CSV como alternativa.\")\n",
    "        print(\"AVISO: CSV não preserva tipos de dados. Considere instalar o pyarrow: pip install pyarrow\")\n",
    "        df_base_ml.to_csv('base_simulada_clientes.csv', index=False, sep=';', decimal=',')\n",
    "        print(\"Base salva em 'base_simulada_clientes.csv'\")\n",
    "\n",
    "    # --- FINAL: ANÁLISE E RETURN (TUDO DENTRO DA FUNÇÃO) ---\n",
    "\n",
    "    print(\"\\n--- Base de ML pronta para treinamento! ---\")\n",
    "\n",
    "    # Colunas de features que o modelo usará:\n",
    "    # A lista features_modelo pode ficar aqui, pois é apenas informativo.\n",
    "    features_modelo = [\n",
    "        # ... (suas features) ...\n",
    "        'gasto_crescim_3m', 'scr_crescim_divida_3m', 'utilizacao_limite_media_3m',\n",
    "        'contagem_rotativo_3m', 'limite_cartao', 'scr_divida_inicial',\n",
    "        'taxa_juros_rotativo', 'taxa_inadimplencia_pf', 'idade_faixa',\n",
    "        'classe_social', 'regiao', 'perfil_investidor'\n",
    "    ]\n",
    " \n",
    "    target = 'entrou_rotativo_proximo_mes'\n",
    " \n",
    "    # Exibir um exemplo de como ficou a base.\n",
    "    # df_clientes é acessível AQUI pois foi criada nesta função.\n",
    "    id_exemplo = df_clientes[df_clientes['grupo_simulacao'] == 'estavel_target'].index[0]\n",
    "\n",
    "    print(\"\\nExemplo de um cliente 'estável_target' (ID: {}):\".format(id_exemplo))\n",
    "    print(df_base_ml[df_base_ml['id_cliente'] == id_exemplo][\n",
    "        ['mes_referencia', 'gasto_total_cartao', 'pagamento_fatura', 'gasto_crescim_3m', 'scr_crescim_divida_3m', 'entrou_rotativo_proximo_mes']\n",
    "    ].tail(10)) # Mostra os últimos 10 meses\n",
    "\n",
    "    print(\"\\nDistribuição da variável alvo (Target):\")\n",
    "    print(df_base_ml[target].value_counts(normalize=True))\n",
    "\n",
    "    # A FUNÇÃO RETORNA A BASE FINAL\n",
    "    return df_base_ml\n",
    "\n",
    "# --- Executar a simulação (Limpo) ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Apenas chama a função principal e armazena o resultado.\n",
    "    df_base_ml = main()\n",
    "    \n",
    "# --- Pré-processamento e Divisão Cronológica ---\n",
    "\n",
    "# 1. Importações (Certifique-se de que estão no início do seu notebook ou neste bloco)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Se estiver usando LightGBM: import lightgbm as lgb\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# 2. Pré-processador (ColumnTransformer para aplicar One-Hot nas categóricas)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # 'passthrough' mantém as features numéricas originais\n",
    "        ('num', 'passthrough', features_numericas), \n",
    "        # 'OneHotEncoder' converte as features categóricas em colunas binárias\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), features_categoricas) \n",
    "    ]\n",
    ")\n",
    "\n",
    "# 3. Preparação dos dados para split\n",
    "X = df_base_ml[features_numericas + features_categoricas]\n",
    "y = df_base_ml[target]\n",
    "\n",
    "# 4. Divisão Cronológica (Usando o mês 18, onde o estresse começa)\n",
    "mes_split = MES_INICIO_ESTRESSE\n",
    "\n",
    "print(f\"\\n--- Divisão Cronológica da Base (Split no mês {mes_split}) ---\")\n",
    "X_train = X[df_base_ml['mes_simulacao'] < mes_split]\n",
    "y_train = y[df_base_ml['mes_simulacao'] < mes_split]\n",
    "\n",
    "X_test = X[df_base_ml['mes_simulacao'] >= mes_split]\n",
    "y_test = y[df_base_ml['mes_simulacao'] >= mes_split]\n",
    "\n",
    "print(f\"Treino (Meses 1-{mes_split-1}): {len(X_train)} observações\")\n",
    "print(f\"Teste (Meses {mes_split}-24): {len(X_test)} observações\")\n",
    "\n",
    "# 5. Aplicar o pré-processamento\n",
    "# O fit_transform deve ser apenas no treino, para evitar vazamento de dados (Data Leakage)\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "# --- Treinamento do Modelo (LightGBM) e Avaliação com Ajuste de Threshold ---\n",
    "\n",
    "# 1. Treinamento\n",
    "# Usando LightGBM por ser rápido e mais robusto em desbalanceamento.\n",
    "# scale_pos_weight = 4 dá 4x mais peso para a Classe 1 (Rotativo), ajudando o Recall.\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    model = lgb.LGBMClassifier(random_state=42, n_jobs=-1, scale_pos_weight=4)\n",
    "    model.fit(X_train_processed, y_train)\n",
    "    print(\"\\nModelo treinado com sucesso (LightGBM com scale_pos_weight=4).\")\n",
    "except ImportError:\n",
    "    # Caso LightGBM não esteja instalado, volte para RandomForest com pesos balanceados\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    model = RandomForestClassifier(random_state=42, class_weight='balanced', n_jobs=-1)\n",
    "    model.fit(X_train_processed, y_train)\n",
    "    print(\"\\nModelo treinado com sucesso (RandomForest com class_weight='balanced').\")\n",
    "    \n",
    "# 2. Prever Probabilidades (Necessário para o ajuste do Threshold)\n",
    "# Queremos a probabilidade da Classe 1 (Rotativo)\n",
    "y_proba = model.predict_proba(X_test_processed)[:, 1]\n",
    "\n",
    "# 3. Ajuste do Threshold (De 0.50 para 0.20, por exemplo)\n",
    "# O limiar de 0.20 significa que, se houver 20% ou mais de chance de Rotativo, damos o alerta.\n",
    "THRESHOLD = 0.20 \n",
    "y_pred_adjusted = (y_proba >= THRESHOLD).astype(int)\n",
    "\n",
    "# 4. Avaliar\n",
    "print(f\"\\n--- Relatório de Classificação (Threshold ajustado para {THRESHOLD}) ---\")\n",
    "print(classification_report(y_test, y_pred_adjusted))\n",
    "\n",
    "# Certifique-se de que os dados X_train_processed, X_test_processed, y_test e y_train foram criados\n",
    "# com a Divisão Cronológica e o One-Hot Encoding antes deste bloco.\n",
    "\n",
    "# --- Treinamento do Modelo (LightGBM) e Avaliação com Ajuste de Threshold ---\n",
    "\n",
    "# 1. Importações e Treinamento\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    # Usamos scale_pos_weight=4 para dar 4x mais importância à Classe 1 (Rotativo)\n",
    "    model = lgb.LGBMClassifier(random_state=42, n_jobs=-1, scale_pos_weight=4)\n",
    "    model.fit(X_train_processed, y_train)\n",
    "    print(\"\\nModelo treinado com sucesso (LightGBM com scale_pos_weight=4).\")\n",
    "except ImportError:\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    # Se LightGBM falhar, usamos RandomForest com peso manual\n",
    "    print(\"\\nAVISO: LightGBM não instalado. Usando RandomForest.\")\n",
    "    model = RandomForestClassifier(random_state=42, class_weight={0: 1, 1: 4}, n_jobs=-1)\n",
    "    model.fit(X_train_processed, y_train)\n",
    "    \n",
    "# 2. Prever Probabilidades (Obrigatório para o Ajuste de Threshold)\n",
    "# Queremos a probabilidade da Classe 1 (Rotativo)\n",
    "y_proba = model.predict_proba(X_test_processed)[:, 1]\n",
    "\n",
    "# 3. Ajuste do Threshold (A \"Inversão de Sinalização\")\n",
    "# Diminuir o limiar de 0.50 para 0.20 (20% de chance já é suficiente para dar o alerta).\n",
    "THRESHOLD = 0.20 \n",
    "y_pred_adjusted = (y_proba >= THRESHOLD).astype(int)\n",
    "\n",
    "# 4. Avaliar o Novo Resultado Otimizado\n",
    "print(f\"\\n--- Relatório de Classificação (Threshold ajustado para {THRESHOLD}) ---\")\n",
    "print(classification_report(y_test, y_pred_adjusted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4353f1",
   "metadata": {},
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c37a519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Relatório de Classificação do Modelo ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.99      0.89     54156\n",
      "           1       0.76      0.09      0.16     14844\n",
      "\n",
      "    accuracy                           0.80     69000\n",
      "   macro avg       0.78      0.54      0.52     69000\n",
      "weighted avg       0.79      0.80      0.73     69000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "# Definir listas de features (Com base no seu código)\n",
    "features_numericas = [\n",
    "    'gasto_crescim_3m', 'scr_crescim_divida_3m', 'utilizacao_limite_media_3m',\n",
    "    'contagem_rotativo_3m', 'limite_cartao', 'scr_divida_inicial',\n",
    "    'taxa_juros_rotativo', 'taxa_inadimplencia_pf'\n",
    "]\n",
    "features_categoricas = [\n",
    "    'idade_faixa', 'classe_social', 'regiao', 'perfil_investidor'\n",
    "]\n",
    "target = 'entrou_rotativo_proximo_mes'\n",
    "\n",
    "MES_INICIO_ESTRESSE = 18 # Definido no seu código\n",
    "mes_split = MES_INICIO_ESTRESSE\n",
    "\n",
    "# Selecionar X e y\n",
    "X = df_base_ml[features_numericas + features_categoricas]\n",
    "y = df_base_ml[target]\n",
    "\n",
    "# Separação cronológica\n",
    "X_train = X[df_base_ml['mes_simulacao'] < mes_split]\n",
    "y_train = y[df_base_ml['mes_simulacao'] < mes_split]\n",
    "\n",
    "X_test = X[df_base_ml['mes_simulacao'] >= mes_split]\n",
    "y_test = y[df_base_ml['mes_simulacao'] >= mes_split]\n",
    "\n",
    "# Aplicar o pré-processamento\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "# Criar o pré-processador (apenas One-Hot para as categóricas)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', features_numericas),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), features_categoricas)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Definir colunas para o modelo\n",
    "features_categoricas = ['idade_faixa', 'classe_social', 'regiao', 'perfil_investidor']\n",
    "features_numericas = [\n",
    "    'gasto_crescim_3m', 'scr_crescim_divida_3m', 'utilizacao_limite_media_3m',\n",
    "    'contagem_rotativo_3m', 'limite_cartao', 'scr_divida_inicial',\n",
    "    'taxa_juros_rotativo', 'taxa_inadimplencia_pf'\n",
    "]\n",
    "target = 'entrou_rotativo_proximo_mes'\n",
    "\n",
    "# Criar o pipeline de pré-processamento\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', features_numericas),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), features_categoricas)\n",
    "    ])\n",
    "\n",
    "# Separar Features (X) e Alvo (y)\n",
    "X = df_base_ml[features_numericas + features_categoricas]\n",
    "y = df_base_ml[target]\n",
    "\n",
    "# Dividir os dados\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Aplicar o pré-processamento\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "# Treinar o Modelo\n",
    "# Usamos class_weight='balanced' pois a base será desbalanceada (poucos entrarão em rotativo)\n",
    "model = RandomForestClassifier(random_state=42, class_weight='balanced', n_jobs=-1)\n",
    "model.fit(X_train_processed, y_train)\n",
    "\n",
    "# Avaliar\n",
    "y_pred = model.predict(X_test_processed)\n",
    "print(\"\\n--- Relatório de Classificação do Modelo ---\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
